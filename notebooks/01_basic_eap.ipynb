{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Basic EAP Walkthrough\n",
    "This notebook demonstrates running simplified EAP on a few toy IOI examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6313147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the repo root (containing `src/` and `data/`) is on sys.path\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "def add_repo_root(marker_dir='src'):\n",
    "    path = os.path.abspath(os.getcwd())\n",
    "    prev = None\n",
    "    while path and path != prev:\n",
    "        if os.path.isdir(os.path.join(path, marker_dir)):\n",
    "            if path not in sys.path:\n",
    "                sys.path.insert(0, path)\n",
    "            return path\n",
    "        prev = path\n",
    "        path = os.path.dirname(path)\n",
    "    # fallback: parent of current working dir\n",
    "    nb_dir = os.path.abspath(os.getcwd())\n",
    "    candidate = os.path.abspath(os.path.join(nb_dir, '..'))\n",
    "    if os.path.isdir(os.path.join(candidate, marker_dir)):\n",
    "        if candidate not in sys.path:\n",
    "            sys.path.insert(0, candidate)\n",
    "        return candidate\n",
    "    return os.path.abspath(os.getcwd())\n",
    "\n",
    "REPO_ROOT = add_repo_root()\n",
    "DATA_PATH = str(Path(REPO_ROOT) / 'data' / 'ioi_examples.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462fe4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "from src.ioi_task import load_ioi_examples\n",
    "from src.circuit_finder import run_eap_on_ioi\n",
    "from src.visualization import plot_head_importance, plot_top_heads_graph\n",
    "\n",
    "model = HookedTransformer.from_pretrained('gpt2-small')\n",
    "examples = load_ioi_examples(DATA_PATH)\n",
    "clean = []\n",
    "corr = []\n",
    "for ex in examples[:8]:\n",
    "    clean.append(model.to_tokens(ex.clean)[0])\n",
    "    corr.append(model.to_tokens(ex.corrupted)[0])\n",
    "clean = torch.nn.utils.rnn.pad_sequence(clean, batch_first=True, padding_value=model.tokenizer.eos_token_id)\n",
    "corr = torch.nn.utils.rnn.pad_sequence(corr, batch_first=True, padding_value=model.tokenizer.eos_token_id)\n",
    "\n",
    "save_dir = Path(REPO_ROOT) / 'results' / 'plots'\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "plot_head_importance(res.head_importance, save_path=str(save_dir / 'head_importance_basic.png'))\n",
    "plot_top_heads_graph(res.head_importance, save_path=str(save_dir / 'top_heads_basic.png'))\n",
    "res.head_importance.max(), res.head_importance.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
