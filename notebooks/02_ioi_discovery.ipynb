{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 - IOI Circuit Discovery with EAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b665ed9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure the repo root (containing `src/` and `data/`) is on sys.path\n",
        "import sys, os\n",
        "from pathlib import Path\n",
        "\n",
        "def add_repo_root(marker_dir='src'):\n",
        "    path = os.path.abspath(os.getcwd())\n",
        "    prev = None\n",
        "    while path and path != prev:\n",
        "        if os.path.isdir(os.path.join(path, marker_dir)):\n",
        "            if path not in sys.path:\n",
        "                sys.path.insert(0, path)\n",
        "            return path\n",
        "        prev = path\n",
        "        path = os.path.dirname(path)\n",
        "    nb_dir = os.path.abspath(os.getcwd())\n",
        "    candidate = os.path.abspath(os.path.join(nb_dir, '..'))\n",
        "    if os.path.isdir(os.path.join(candidate, marker_dir)):\n",
        "        if candidate not in sys.path:\n",
        "            sys.path.insert(0, candidate)\n",
        "        return candidate\n",
        "    return os.path.abspath(os.getcwd())\n",
        "\n",
        "REPO_ROOT = add_repo_root()\n",
        "DATA_PATH = str(Path(REPO_ROOT) / 'data' / 'ioi_examples.json')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41ac9bb3",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformer_lens import HookedTransformer\n",
        "from src.ioi_task import load_ioi_examples\n",
        "from src.circuit_finder import run_eap_on_ioi\n",
        "from src.visualization import plot_head_importance, plot_top_heads_graph\n",
        "\n",
        "model = HookedTransformer.from_pretrained('gpt2-small')\n",
        "examples = load_ioi_examples(DATA_PATH)\n",
        "clean_ids = []\n",
        "corr_ids = []\n",
        "for ex in examples:\n",
        "    clean_ids.append(model.to_tokens(ex.clean)[0])\n",
        "    corr_ids.append(model.to_tokens(ex.corrupted)[0])\n",
        "clean = torch.nn.utils.rnn.pad_sequence(clean_ids, batch_first=True, padding_value=model.tokenizer.eos_token_id)\n",
        "corr = torch.nn.utils.rnn.pad_sequence(corr_ids, batch_first=True, padding_value=model.tokenizer.eos_token_id)\n",
        "\n",
        "res = run_eap_on_ioi(model, clean, corr, target_token_idx=-1)\n",
        "plot_head_importance(res.head_importance, save_path='results/plots/head_importance_ioi.png')\n",
        "plot_top_heads_graph(res.head_importance, save_path='results/plots/top_heads_ioi.png')\n",
        "res.baseline_delta, res.head_importance.shape\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
